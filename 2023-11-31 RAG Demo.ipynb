{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Andrei-Larionov/RAGTest/blob/main/2023-11-31%20RAG%20Demo.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbWAIclyoNFP"
      },
      "source": [
        "# Document Question Answering with LlamaIndex, OpenAI and Redis\n",
        "\n",
        "![Redis](https://redis.com/wp-content/themes/wpx/assets/images/logo-redis.svg?auto=webp&quality=85,75&width=120)\n",
        "\n",
        "This notebook would use OpenAI, Redis with Vector Similarity Search and LlamaIndex to answer questions about the information contained in a document."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "1W9kTV8gdOuA",
        "outputId": "33d2ceff-a4db-4b1d-e374-ef8487c205fa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m917.6/917.6 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.3/250.3 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.0/143.0 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.0/75.0 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m220.9/220.9 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m24.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.5/44.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.7/40.7 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m837.8/837.8 kB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m263.8/263.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m31.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.9/76.9 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: llama-index in /usr/local/lib/python3.10/dist-packages (0.9.10)\n",
            "Requirement already satisfied: SQLAlchemy[asyncio]>=1.4.49 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.0.23)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.6 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.6)\n",
            "Requirement already satisfied: aiostream<0.6.0,>=0.5.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.5.2)\n",
            "Requirement already satisfied: beautifulsoup4<5.0.0,>=4.12.2 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.12.2)\n",
            "Requirement already satisfied: dataclasses-json in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.6.3)\n",
            "Requirement already satisfied: deprecated>=1.2.9.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.2.14)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2023.6.0)\n",
            "Requirement already satisfied: httpx in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.25.2)\n",
            "Requirement already satisfied: nest-asyncio<2.0.0,>=1.5.8 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.8)\n",
            "Requirement already satisfied: nltk<4.0.0,>=3.8.1 in /usr/local/lib/python3.10/dist-packages (from llama-index) (3.8.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.23.5)\n",
            "Requirement already satisfied: openai>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from llama-index) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.2.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (8.2.3)\n",
            "Requirement already satisfied: tiktoken>=0.3.3 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.5.1)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (4.5.0)\n",
            "Requirement already satisfied: typing-inspect>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from llama-index) (0.9.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.6->llama-index) (1.3.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4<5.0.0,>=4.12.2->llama-index) (2.5)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from deprecated>=1.2.9.3->llama-index) (1.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk<4.0.0,>=3.8.1->llama-index) (4.66.1)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai>=1.1.0->llama-index) (1.7.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (1.10.13)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai>=1.1.0->llama-index) (1.3.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (1.0.2)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx->llama-index) (3.4)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx->llama-index) (0.14.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.31.0->llama-index) (2.0.7)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy[asyncio]>=1.4.49->llama-index) (3.0.1)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect>=0.8.0->llama-index) (1.0.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json->llama-index) (3.20.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->llama-index) (2023.3.post1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai>=1.1.0->llama-index) (1.1.3)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->llama-index) (23.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->llama-index) (1.16.0)\n",
            "Collecting docx2txt\n",
            "  Downloading docx2txt-0.8.tar.gz (2.8 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: docx2txt\n",
            "  Building wheel for docx2txt (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for docx2txt: filename=docx2txt-0.8-py3-none-any.whl size=3960 sha256=c9bb718936b7ddad075744b95e36324d520784455fb8a385695fb3f11aebc7f0\n",
            "  Stored in directory: /root/.cache/pip/wheels/22/58/cf/093d0a6c3ecfdfc5f6ddd5524043b88e59a9a199cb02352966\n",
            "Successfully built docx2txt\n",
            "Installing collected packages: docx2txt\n",
            "Successfully installed docx2txt-0.8\n"
          ]
        }
      ],
      "source": [
        "!pip install -q llama_index redis html2text trafilatura\n",
        "!pip install llama-index\n",
        "!pip install docx2txt\n",
        "!pip install -q pypdf\n",
        "from llama_index import SimpleDirectoryReader\n",
        "from IPython.display import Markdown, display"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "b855h60jdL8y"
      },
      "outputs": [],
      "source": [
        "from llama_index import (\n",
        "      GPTVectorStoreIndex,\n",
        "      StorageContext,\n",
        "      ServiceContext\n",
        "    )\n",
        "from llama_index.vector_stores import RedisVectorStore\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "5y30hjJunmC8"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "\n",
        "import logging\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO) # logging.DEBUG for more verbose output\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "efBhX9rClb51"
      },
      "source": [
        "Initialize OpenAI. You need to supply the OpenAI API key (starts with `sk-...`) when prompted. You can find your API key at https://platform.openai.com/account/api-keys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "iU2xMRwmeTn_",
        "outputId": "7c557700-678c-4066-93e1-e2a9c381fcdd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI Key: ··········\n"
          ]
        }
      ],
      "source": [
        "import openai\n",
        "import os\n",
        "import getpass\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\",\"\")\n",
        "if OPENAI_API_KEY == \"\":\n",
        "    key=getpass.getpass(prompt='OpenAI Key: ', stream=None)\n",
        "    os.environ['OPENAI_API_KEY']=key\n",
        "\n",
        "openai.api_key = os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJ9_U6bNlb52"
      },
      "source": [
        "### Install Redis Stack\n",
        "\n",
        "Redis Search will be used as Vector Similarity Search engine for LangChain. Instead of using in-notebook Redis Stack https://redis.io/docs/getting-started/install-stack/ you can provision your own free instance of Redis in the cloud. Get your own Free Redis Cloud instance at https://redis.com/try-free/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fowy4iKxgrTR",
        "outputId": "d057f6da-f62f-4b29-d4fa-10038e2fbea1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb jammy main\n",
            "Starting redis-stack-server, database path /var/lib/redis-stack\n"
          ]
        }
      ],
      "source": [
        "%%sh\n",
        "curl -fsSL https://packages.redis.io/gpg | sudo gpg --dearmor -o /usr/share/keyrings/redis-archive-keyring.gpg\n",
        "echo \"deb [signed-by=/usr/share/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/redis.list\n",
        "sudo apt-get update  > /dev/null 2>&1\n",
        "sudo apt-get install redis-stack-server  > /dev/null 2>&1\n",
        "redis-stack-server --daemonize yes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "35qGare8lb53"
      },
      "source": [
        "### Connect to Redis\n",
        "\n",
        "By default this notebook would connect to the local instance of Redis Stack. If you have your own Redis Cloud instance - replace REDIS_PASSWORD, REDIS_HOST and REDIS_PORT values with your own."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "Ww9kR1QegsQV"
      },
      "outputs": [],
      "source": [
        "import redis\n",
        "import os\n",
        "\n",
        "\n",
        "REDIS_HOST = os.getenv(\"REDIS_HOST\", \"localhost\")\n",
        "REDIS_PORT = os.getenv(\"REDIS_PORT\", \"6379\")\n",
        "REDIS_PASSWORD = os.getenv(\"REDIS_PASSWORD\", \"\")\n",
        "#Replace values above with your own if using Redis Cloud instance\n",
        "#REDIS_HOST=\"redis-18374.c253.us-central1-1.gce.cloud.redislabs.com\"\n",
        "#REDIS_PORT=18374\n",
        "#REDIS_PASSWORD=\"1TNxTEdYRDgIDKM2gDfasupCADXXXX\"\n",
        "\n",
        "#shortcut for redis-cli $REDIS_CONN command\n",
        "if REDIS_PASSWORD!=\"\":\n",
        "  os.environ[\"REDIS_CONN\"]=f\"-h {REDIS_HOST} -p {REDIS_PORT} -a {REDIS_PASSWORD} --no-auth-warning\"\n",
        "else:\n",
        "  os.environ[\"REDIS_CONN\"]=f\"-h {REDIS_HOST} -p {REDIS_PORT}\"\n",
        "\n",
        "REDIS_URL = f\"redis://:{REDIS_PASSWORD}@{REDIS_HOST}:{REDIS_PORT}\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVX_BvJplb54"
      },
      "source": [
        "### Load web documents\n",
        "\n",
        "Load web documents that would be used to answer questions. Feel free to replace the links with the ones you would like to use."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "documents = SimpleDirectoryReader('./docs').load_data()"
      ],
      "metadata": {
        "id": "zb_Jq9VVnFHZ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "QUv3aBIUeoKv",
        "outputId": "f75adab4-71b4-4fe4-ac6b-05b37a308bb3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "205"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "len(documents)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYER6y5blb54"
      },
      "source": [
        "### Create vector store using Redis as Vector Database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2fyVyFvBh7LS",
        "outputId": "49cfa167-f429-426a-a8c9-6cb32be8eb44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using Redis address: redis://:@localhost:6379\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "print(f\"Using Redis address: {REDIS_URL}\")\n",
        "vector_store = RedisVectorStore(\n",
        "    index_name=\"news\",\n",
        "    index_prefix=\"cnn\",\n",
        "    redis_url=REDIS_URL,\n",
        "    overwrite=True\n",
        ")\n",
        "vector_store.client.ping()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YBU8uIXyizsB",
        "outputId": "ed240942-991e-4d93-f9c4-d50fae15c19f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /tmp/llama_index...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ],
      "source": [
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
        "service_context = ServiceContext.from_defaults(chunk_size=1000, chunk_overlap=200)\n",
        "index = GPTVectorStoreIndex.from_documents(\n",
        "    documents,\n",
        "    service_context=service_context,\n",
        "    storage_context=storage_context\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q8s1l-W-lb55"
      },
      "source": [
        "## Finally - let's ask questions!\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "id": "3QKwKOrkdbRV",
        "outputId": "5c6601f4-f0f7-49df-a0ec-576c144cbe67"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "ANSYS made money in 2022. The earnings per share for 2022 were $6.02 (basic) and $5.99 (diluted). In terms of cash flow, the net cash provided by operating activities in 2022 was $631,003."
          },
          "metadata": {}
        }
      ],
      "source": [
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"Did ansys make any money in 2022 ? Please provide earnings per share and cash flow\")\n",
        "display(Markdown(f\"{response}\"))\n",
        "#print(response)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response"
      ],
      "metadata": {
        "id": "pRrtulXOoyyh",
        "outputId": "fd4a2e51-a3f9-4c3e-d751-f48d8c2ad0bb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Response(response=\"To mesh the geometry in ANSYS Fluent, follow these step-by-step instructions:\\n\\n1. Open ANSYS Fluent and navigate to the File menu.\\n2. Select the Import option and choose the appropriate file format for your geometry (e.g., I-deas or NASTRAN).\\n3. Follow the instructions to import the geometry file into ANSYS Fluent.\\n4. Once the geometry is imported, go to the Mesh menu and select the appropriate meshing option.\\n5. Choose the desired meshing method based on your requirements (e.g., volume mesh with linear triangular, quadrilateral, tetrahedral, wedge, or hexahedral elements).\\n6. Configure the meshing parameters, such as element size, element type, and mesh quality criteria.\\n7. Click on the Generate Mesh button to generate the mesh for the geometry.\\n8. After the mesh is generated, you can further refine the mesh if needed by using smoothing and swapping techniques.\\n9. Review the mesh quality and make any necessary adjustments to improve the mesh quality.\\n10. Save the mesh file in the desired format for future use or analysis.\\n\\nPlease note that the specific steps may vary depending on the version of ANSYS Fluent you are using. It is recommended to refer to the ANSYS Fluent User's Guide for detailed instructions specific to your version.\", source_nodes=[NodeWithScore(node=TextNode(id_='aa6e19d0-6e08-4d46-8868-ff13588dcff8', embedding=None, metadata={'file_name': \"ANSYS FLUENT 14.0 User's Guide.docx\", 'file_path': \"docs/ANSYS FLUENT 14.0 User's Guide.docx\", 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 24838106, 'creation_date': '2023-11-30', 'last_modified_date': '2023-11-30', 'last_accessed_date': '2023-11-30'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='de62aa32-cbfa-41db-8f07-d00bf9a1b2f0', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_name': \"ANSYS FLUENT 14.0 User's Guide.docx\", 'file_path': \"docs/ANSYS FLUENT 14.0 User's Guide.docx\", 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 24838106, 'creation_date': '2023-11-30', 'last_modified_date': '2023-11-30', 'last_accessed_date': '2023-11-30'}, hash='3573de0bbc18b8e1745c40aca14543d95efc1f492c0e7e34112c17d767ee44c1'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='c84a1ad1-46a1-483f-a145-45ff986ba19d', node_type=<ObjectType.TEXT: '1'>, metadata={'file_name': \"ANSYS FLUENT 14.0 User's Guide.docx\", 'file_path': \"docs/ANSYS FLUENT 14.0 User's Guide.docx\", 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 24838106, 'creation_date': '2023-11-30', 'last_modified_date': '2023-11-30', 'last_accessed_date': '2023-11-30'}, hash='5ff10edf3c4cce41d57e57b2b4da3f11905f2a4f366b5db796e7992fa3a93cc3'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='87046c03-e153-4904-93e5-1e68b4e06a52', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='dd088cbc98a750c1f7aebba7baa6971c8bba9729bdc334328a459d58bf145c75')}, hash='94022755ace895efbe93a8c2ab0565f9da0e43190dd7091bcb1972e61c17b1a8', text='(optional) If you want to create a graphical animation of the mesh over time during the solution pro- cedure, you can use the Calculation Activities Task Page (p. 2093) to set up the graphical displays that you want to use in the animation. See Animating the Solution (p. 1409) for details.\\n\\n\\n\\nFor additional information, please see the following sections:\\n\\n\\tSetting Dynamic Mesh Modeling Parameters\\n\\n\\tDynamic Mesh Update Methods\\n\\n\\tIn-Cylinder Settings\\n\\n\\tSix DOF Solver Settings\\n\\n\\tImplicit Update Settings\\n\\n\\tDefining Dynamic Mesh Events\\n\\n\\tSpecifying the Motion of Dynamic Zones\\n\\n\\tPreviewing the Dynamic Mesh\\n\\n\\tSteady-State Dynamic Mesh Applications\\n\\n\\n\\n\\tSetting Dynamic Mesh Modeling Parameters\\n\\nTo enable the dynamic mesh model, enable Dynamic Mesh in the Dynamic Mesh Task Page (p. 2024) (Figure 11.13 (p. 575)).\\n\\n\\n\\n\\tDynamic Mesh →\\tDynamic Mesh\\n\\nThen, enable the appropriate options in the Options group box. If you are modeling in-cylinder motion, enable the In-Cylinder option. If you are going to use the six degrees of freedom solver, then enable the Six DOF option. If you are want to have the dynamic mesh updated during a time step (as opposed to just at the beginning of a time step), then enable the Implicit Update option. More information about these options and the related settings can be found in In-Cylinder Settings (p. 618), Six DOF Solver Settings (p. 633), and Implicit Update Settings (p. 635), respectively.\\n\\n\\n\\nNext, you will need to select the appropriate mesh update methods in the Mesh Methods group box, and set the associated parameters, if relevant. See Dynamic Mesh Update Methods (p. 575) for details.\\n\\n\\n\\n\\n\\nFigure 11.13 The Dynamic Mesh Task Page\\n\\n\\n\\n\\n\\n\\tDynamic Mesh Update Methods\\n\\nThree groups of mesh motion methods are available in ANSYS FLUENT to update the volume mesh in the deforming regions subject to the motion defined at the boundaries:\\n\\n\\t\\tSmoothing Methods (p. 575)\\n\\n\\t\\tDynamic Layering (p. 591)\\n\\n\\t\\tRemeshing Methods (p. 595)\\n\\n\\n\\nNote that you can use ANSYS FLUENT’s dynamic mesh models in conjunction with hanging node adap- tion, with the exception of dynamic layering and face remeshing. For more information on hanging node adaption, see Hanging Node Adaption in the Theory Guide.\\n\\n\\n\\nDetails on how to set up the various dynamic mesh update methods are provided in the sections that follow.\\n\\n\\n\\n\\tSmoothing Methods\\n\\nTo enable smoothing, perform the following steps:\\n\\n\\t\\tEnable the Smoothing option in the Mesh Methods group box of the Dynamic Mesh Task Page (p. 2024).\\n\\n\\n\\n\\n\\n\\t\\tClick the Settings... button to open the Mesh Method Settings dialog box.\\n\\n\\n\\nFigure 11.14 The Smoothing Tab of the Mesh Method Settings Dialog Box\\n\\n\\n\\n\\t\\tIf you want spring-based smoothing, select Spring/Laplace/Boundary Layer from the Method list and define the settings in the Parameters group box, which are described in Spring-Based Smoothing (p. 577).\\n\\n\\t\\tIf you want diffusion-based smoothing (described in Diffusion-Based Smoothing (p. 581)):\\n\\n\\t\\tSelect Diffusion from the Method list .\\n\\n\\t\\tMake a selection from the Diffusion Function drop-down list, to indicate whether you want the diffusion coefficient to be a function of the boundary-distance or the cell-volume. These functions and suggested values for the Diffusion Parameter are described in Diffusivity Based on Boundary Distance (p. 583) and Diffusivity Based on Cell Volume (p. 585).\\n\\n\\t\\tIf you plan to apply the 2.5D remeshing method, perform the following steps to set up Laplacian smoothing (as described in Laplacian Smoothing Method (p. 586)).\\n\\n\\t\\tSelect Spring/Laplace/Boundary Layer from the Method list\\n\\n\\t\\tDefine only the Boundary Node Relaxation and Number of Iterations in the Parameters group box (the other settings are not relevant).\\n\\n\\t\\tIf you plan to apply the boundary layer smoothing method (as described in Boundary Layer Smoothing Method (p. 587)), select Spring/Laplace/Boundary Layer from the Method list.\\n\\n\\n\\n\\n\\n\\tSpring-Based Smoothing\\n\\nFor spring-based smoothing, the edges between any two mesh nodes are idealized as a network of interconnected springs. The initial spacings of the edges before any boundary motion constitute the equilibrium state of the mesh. A displacement at a given boundary node will generate a force propor- tional to the displacement along all the springs connected to the node. Using Hook’s Law, the force on a mesh node can be written as', start_char_idx=1249632, end_char_idx=1253995, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.839145123959), NodeWithScore(node=TextNode(id_='62076dee-c882-4733-a2a5-803ad5f79648', embedding=None, metadata={'file_name': \"ANSYS FLUENT 14.0 User's Guide.docx\", 'file_path': \"docs/ANSYS FLUENT 14.0 User's Guide.docx\", 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 24838106, 'creation_date': '2023-11-30', 'last_modified_date': '2023-11-30', 'last_accessed_date': '2023-11-30'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='de62aa32-cbfa-41db-8f07-d00bf9a1b2f0', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_name': \"ANSYS FLUENT 14.0 User's Guide.docx\", 'file_path': \"docs/ANSYS FLUENT 14.0 User's Guide.docx\", 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 24838106, 'creation_date': '2023-11-30', 'last_modified_date': '2023-11-30', 'last_accessed_date': '2023-11-30'}, hash='3573de0bbc18b8e1745c40aca14543d95efc1f492c0e7e34112c17d767ee44c1'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='9ac77eeb-bc69-4532-a27c-a2cacaa8a9da', node_type=<ObjectType.TEXT: '1'>, metadata={'file_name': \"ANSYS FLUENT 14.0 User's Guide.docx\", 'file_path': \"docs/ANSYS FLUENT 14.0 User's Guide.docx\", 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 24838106, 'creation_date': '2023-11-30', 'last_modified_date': '2023-11-30', 'last_accessed_date': '2023-11-30'}, hash='d9f51a9901590dc87db1d1227646390f7a982347962aadcb60c403474e741ff1'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='021e3113-1c4b-4c8d-b8ce-2dd8e9f63045', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='8b4ccc9b4183e1ef6ce1b90d75102b18aed9ab74ead5bceb34c7ff778d6442be')}, hash='94022755ace895efbe93a8c2ab0565f9da0e43190dd7091bcb1972e61c17b1a8', text=\"Generate an I-deas volume mesh with linear triangular, quadrilateral, tetrahedral, wedge, or hexahedral elements. Import it directly using the File/Import/I-deas Universal... menu item, as described in I-deas Universal Files (p. 83).\\n\\n\\t\\tGenerate an I-deas volume mesh with linear triangular, quadrilateral, tetrahedral, wedge, or hexahedral elements. Use the fe2ram filter to convert the Universal file to the format used by ANSYS FLUENT. To convert an input file in I-deas Universal format to an output file in ANSYS FLUENT format, follow the instructions below in Using the fe2ram Filter to Convert Files (p. 155). After the output file is written, read it into ANSYS FLUENT using the File/Read/Mesh... menu item, as described in Reading Mesh Files (p. 64).\\n\\n\\n\\n\\tRecognized I-deas Datasets\\n\\nThe following Universal file datasets are recognized by the ANSYS FLUENT mesh import utility:\\n\\n\\t\\tNode Coordinates dataset number 15, 781, 2411\\n\\n\\t\\tElements dataset number 71, 780, 2412\\n\\n\\t\\t\\tPermanent Groups dataset number 752, 2417, 2429, 2430, 2432, 2435 For 2D volume meshes, the elements must exist in a constant\\tplane.\\n\\n\\n\\nNote\\n\\n\\n\\nThe mesh area or mesh volume datasets are not recognized. This implies that writing multiple mesh areas/volumes to a single Universal file may confuse ANSYS FLUENT.\\n\\n\\n\\n\\tGrouping Nodes to Create Face Zones\\n\\nNodes are grouped in I-deas using the Group command to create boundary face zones. In ANSYS FLUENT, boundary conditions are applied to each zone. Faces that contain the nodes in a group are gathered into a single zone. It is important not to group nodes of internal faces with nodes of boundary faces.\\n\\n\\n\\nOne technique is to generate groups automatically based on curves or mesh areas—i.e., every curve or mesh area will be a different zone in ANSYS FLUENT. You may also create the groups manually, gener- ating groups consisting of all nodes related to a given curve (2D) or mesh area (3D).\\n\\n\\n\\n\\tGrouping Elements to Create Cell Zones\\n\\nElements in I-deas are grouped using the Group command to create the multiple cell zones. All elements grouped together are placed in a single cell zone in ANSYS FLUENT. If the elements are not grouped, ANSYS FLUENT will place all the cells into a single zone.\\n\\n\\n\\n\\tDeleting Duplicate Nodes\\n\\nI-deas may generate duplicate or coincident nodes in the process of creating elements. These nodes must be removed in I-deas before writing the universal file for import into ANSYS FLUENT.\\n\\n\\tNASTRAN Files\\n\\nThere are three different ways in which you can import a NASTRAN file into ANSYS FLUENT:\\n\\n\\t\\tYou can generate a NASTRAN surface or volume mesh containing triangular, quadrilateral, tetrahedral, wedge, and/or hexahedral elements, and import it into TGrid using the commands described in the\\n\\n\\n\\n\\n\\nTGrid User's Guide and adhering to the restrictions described in Appendix B of the TGrid User's Guide. In TGrid, complete the mesh generation (if necessary) and then follow the instructions in TGrid Mesh Files (p. 149).\\n\\n\\tYou can generate a NASTRAN volume mesh with linear triangular, quadrilateral, tetrahedral, wedge, or hexahedral elements, and import it directly using the File/Import/NASTRAN menu item, as described in NASTRAN Files (p. 84).\\n\\n\\t\\tYou can generate a NASTRAN volume mesh with linear triangular, quadrilateral, tetrahedral, wedge, or hexahedral elements. Then use the fe2ram filter to convert the NASTRAN file to the format used by ANSYS FLUENT. To convert an input file in NASTRAN format to an output file in ANSYS FLUENT format, follow the instructions below in Using the fe2ram Filter to Convert Files (p. 155). After the output file has been written, you can read it into ANSYS FLUENT using the File/Read/Mesh... menu item, as described in Reading Mesh Files (p. 64).\\n\\n\\n\\nAfter reading a triangular or tetrahedral NASTRAN volume mesh using the latter methods perform smoothing and swapping (as described in Improving the Mesh by Smoothing and Swapping (p. 1466)) to improve its quality.\", start_char_idx=437638, end_char_idx=441601, text_template='{metadata_str}\\n\\n{content}', metadata_template='{key}: {value}', metadata_seperator='\\n'), score=0.835895180702)], metadata={'aa6e19d0-6e08-4d46-8868-ff13588dcff8': {'file_name': \"ANSYS FLUENT 14.0 User's Guide.docx\", 'file_path': \"docs/ANSYS FLUENT 14.0 User's Guide.docx\", 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 24838106, 'creation_date': '2023-11-30', 'last_modified_date': '2023-11-30', 'last_accessed_date': '2023-11-30'}, '62076dee-c882-4733-a2a5-803ad5f79648': {'file_name': \"ANSYS FLUENT 14.0 User's Guide.docx\", 'file_path': \"docs/ANSYS FLUENT 14.0 User's Guide.docx\", 'file_type': 'application/vnd.openxmlformats-officedocument.wordprocessingml.document', 'file_size': 24838106, 'creation_date': '2023-11-30', 'last_modified_date': '2023-11-30', 'last_accessed_date': '2023-11-30'}})"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}